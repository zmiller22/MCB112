{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2\n",
    "## \"The adventure of ten Arcs\"\n",
    "### Zachary Miller\n",
    "\n",
    "## Part 1: Repoducing Moriarty's Results\n",
    "The first thing we want to do is to reproduce Moriarty's result using kallisto on the original data. First, let's run the kallisto command with no arguments to get the usage information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kallisto 0.46.0\r\n",
      "\r\n",
      "Usage: kallisto <CMD> [arguments] ..\r\n",
      "\r\n",
      "Where <CMD> can be one of:\r\n",
      "\r\n",
      "    index         Builds a kallisto index \r\n",
      "    quant         Runs the quantification algorithm \r\n",
      "    bus           Generate BUS files for single-cell data \r\n",
      "    pseudo        Runs the pseudoalignment step \r\n",
      "    merge         Merges several batch runs \r\n",
      "    h5dump        Converts HDF5-formatted results to plaintext\r\n",
      "    inspect       Inspects and gives information about an index\r\n",
      "    version       Prints version information\r\n",
      "    cite          Prints citation information\r\n",
      "\r\n",
      "Running kallisto <CMD> without arguments prints usage information for <CMD>\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! kallisto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is mentioned in the lecture notes, we are most interested in the `index` and `quant` commands, which we will use to reproduce Moriarty's expirement below. Notice that we tweaked the arguments to match Moriarty's expirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file arc.fasta.gz\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 19 contigs and contains 10000 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 10,000\n",
      "[index] number of equivalence classes: 26\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: arc.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,983 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 58 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! kallisto index -i moriarty_transcripts.idx arc.fasta.gz\n",
    "! kallisto quant -i moriarty_transcripts.idx -o moriarty_output --single -l 150 -s 20 arc.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the output of kallisto to make sure it matches the results Moriarty got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>length</th>\n",
       "      <th>eff_length</th>\n",
       "      <th>est_counts</th>\n",
       "      <th>tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arc1</td>\n",
       "      <td>4000</td>\n",
       "      <td>3851</td>\n",
       "      <td>2810.71</td>\n",
       "      <td>20570.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arc2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1851</td>\n",
       "      <td>3640.85</td>\n",
       "      <td>55436.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arc3</td>\n",
       "      <td>3000</td>\n",
       "      <td>2851</td>\n",
       "      <td>28233.50</td>\n",
       "      <td>279105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arc4</td>\n",
       "      <td>4000</td>\n",
       "      <td>3851</td>\n",
       "      <td>10376.20</td>\n",
       "      <td>75939.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arc5</td>\n",
       "      <td>4000</td>\n",
       "      <td>3851</td>\n",
       "      <td>12912.90</td>\n",
       "      <td>94504.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arc6</td>\n",
       "      <td>3000</td>\n",
       "      <td>2851</td>\n",
       "      <td>1983.17</td>\n",
       "      <td>19604.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arc7</td>\n",
       "      <td>2000</td>\n",
       "      <td>1851</td>\n",
       "      <td>5442.49</td>\n",
       "      <td>82868.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arc8</td>\n",
       "      <td>2000</td>\n",
       "      <td>1851</td>\n",
       "      <td>5635.31</td>\n",
       "      <td>85804.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arc9</td>\n",
       "      <td>3000</td>\n",
       "      <td>2851</td>\n",
       "      <td>3082.56</td>\n",
       "      <td>30472.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arc10</td>\n",
       "      <td>3000</td>\n",
       "      <td>2851</td>\n",
       "      <td>25865.20</td>\n",
       "      <td>255693.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id  length  eff_length  est_counts       tpm\n",
       "0      Arc1    4000        3851     2810.71   20570.4\n",
       "1      Arc2    2000        1851     3640.85   55436.5\n",
       "2      Arc3    3000        2851    28233.50  279105.0\n",
       "3      Arc4    4000        3851    10376.20   75939.3\n",
       "4      Arc5    4000        3851    12912.90   94504.2\n",
       "5      Arc6    3000        2851     1983.17   19604.8\n",
       "6      Arc7    2000        1851     5442.49   82868.8\n",
       "7      Arc8    2000        1851     5635.31   85804.8\n",
       "8      Arc9    3000        2851     3082.56   30472.9\n",
       "9     Arc10    3000        2851    25865.20  255693.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m_data = pd.read_csv('moriarty_output/abundance.tsv', delim_whitespace=True)\n",
    "m_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the tpm column, we see that kallisto is giving us tpm counts that are about $\\pm500$ what Moriarty reported, and are certainly much closer to Moriarty's tpm counts than the ones we reported. \n",
    "\n",
    "## Part 2: Creating a RNA-Seq Simulator\n",
    "\n",
    "Now, we decide that we want to test how well kallisto works when we feed it simulated data, since when we simulate data we have a sort of \"God's eye\" view and get to know the correct answer. To do so, we will write three functions. The first function will generate a synthetic Arc locus according to the paramters given in the problem statement. The second function will then create the simulated transcriptome from that Arc locus, using either the transcript lengths we found in our expirement, or randomly generated transcript lengths that are between 2 and 4 (inclusive) segments long. This function should write the transcriptome to a FASTA file and return the transcriptome as a 2d list. Lastly, we will need a third function that uses the transcriptome to generate the reads that will be fed into Kallisto, keeping in mind how the mRNA sequences are broken into reads in the actual expirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "import random\n",
    "rand.seed(42)\n",
    "\n",
    "# A few handy functions for this PSET\n",
    "def trunc_gaussian(mean, sd, max_sample, min_sample):\n",
    "    \"\"\"Returns an integer sampled from a guassian distribution with mean=mean and standard deviation = sd,\n",
    "    truncated to be between max_sample and min_sample (inclusive)\"\"\"\n",
    "    while True:\n",
    "        sample = int(rand.normal(mean, sd))\n",
    "        if sample >= min_sample: break\n",
    "    \n",
    "    if sample > max_sample: sample = max_sample\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def reverse_comp(seq):\n",
    "    \"\"\"Returns the reverse compliment of a DNA sequence given as a string of the characters A C G T\"\"\"\n",
    "    seq = seq[::-1]\n",
    "    new_seq = \"\"\n",
    "    for c in seq:\n",
    "        if c == \"A\":\n",
    "            new_seq += \"T\"\n",
    "        elif c == \"C\":\n",
    "            new_seq += \"G\"\n",
    "        elif c == \"G\":\n",
    "            new_seq += \"C\"\n",
    "        elif c == \"T\":\n",
    "            new_seq += \"A\"\n",
    "            \n",
    "    return new_seq\n",
    "\n",
    "def base_error(seq, alpha):\n",
    "    \"\"\"Given a sequence seq and a base calling error rate alpha, will generate base calling errors in the \n",
    "    sequence at a probability equal to alpha\"\"\"\n",
    "    new_seq = \"\"\n",
    "    for base in seq:\n",
    "        if rand.uniform(0,1) <= alpha:\n",
    "            if base == \"A\":\n",
    "                new_seq += rand.choice([\"C\",\"G\",\"T\"])\n",
    "            elif base == \"C\":\n",
    "                new_seq += rand.choice([\"A\",\"G\",\"T\"])\n",
    "            elif base == \"G\":\n",
    "                new_seq += rand.choice([\"A\",\"C\",\"T\"])\n",
    "            elif base == \"T\":\n",
    "                new_seq += rand.choice([\"A\",\"C\",\"G\"])\n",
    "        \n",
    "        else: new_seq += base\n",
    "        \n",
    "    return new_seq \n",
    "\n",
    "def calc_correct_tpm(nt_abunds, lengths):\n",
    "    nt_abunds = np.array(nt_abunds)\n",
    "    lengths = np.array(lengths)\n",
    "    correct_tpm = []\n",
    "    for idx, abund in enumerate(nt_abunds):\n",
    "        fac_1 = abund/lengths[idx]\n",
    "        fac_2 = sum(nt_abunds/lengths)\n",
    "        correct_tpm.append((fac_1/fac_2)*(10**6))\n",
    "    correct_tpm = [round(i,1) for i in correct_tpm]    \n",
    "        \n",
    "    return correct_tpm\n",
    "\n",
    "# Arc locus parameters\n",
    "S         = 10           # Number of segments in the Arc locus (A..J)\n",
    "T         = S            # Number of different transcripts (the same, one starting on each segment, 1..10)\n",
    "N         = 100000       # total number of observed reads we generate\n",
    "alpha     = 0.999        # base calling accuracy (Q30 bases, typical of current Illumina)\n",
    "S_len     = 1000         # length of each segment (nucleotides)\n",
    "Arc_len   = S_len * S    # total length of the Arc locus (nucleotides)\n",
    "R_len     = 75           # read length\n",
    "frag_mean = 150          # fragment size: mean (of a truncated Gaussian)\n",
    "frag_sd   = 20           # fragment size: stdev\n",
    "bp_list   = [\"A\", \"C\",\n",
    "            \"G\", \"T\"]\n",
    "bp_probs  = [0.25, 0.25, # base pair probabilities in order: A C G T\n",
    "            0.25, 0.25]\n",
    "\n",
    "# Transcription parameters\n",
    "v         = [0.008, 0.039, # default nucleotide abundances (equal to what we got from our expirement)\n",
    "            0.291, 0.112,\n",
    "            0.127, 0.008,\n",
    "            0.059, 0.060,\n",
    "            0.022, 0.273]\n",
    "\n",
    "L         = [4000, 2000,   # default transcript lengths\n",
    "            3000, 4000, \n",
    "            4000, 3000,\n",
    "            2000, 2000,\n",
    "            3000, 3000]\n",
    "\n",
    "v_norm    = [i/sum(v) for  # value of v normalized to add up to one\n",
    "            i in v] \n",
    "\n",
    "def create_arc_loc(new_arc_length):\n",
    "    \"\"\"Creates a DNA seqeunce, if user enters new_arc_length as False, it creates an arc locus according to \n",
    "    the length parameter above. If instead the user provides a specific length, then this returns an arc_locus\n",
    "    of that length\"\"\"\n",
    "    if new_arc_length == False:\n",
    "        arc_locus = [\"\"]*Arc_len\n",
    "    \n",
    "    else: arc_locus = [\"\"]*new_arc_length\n",
    "    \n",
    "    for idx, element in enumerate(arc_locus):\n",
    "        arc_locus[idx] = rand.choice(bp_list, p=bp_probs)\n",
    "    \n",
    "    return arc_locus\n",
    "\n",
    "def create_arc_transcriptome(arc_locus, use_default_lengths, file_name):\n",
    "    \"\"\"Creates a tanscriptome based off an arc locus given as an input and outputs it to a FASTA file with \n",
    "    name \"output\". use_defualt_lengths allows the user to use the hardcoded lengths v by setting the \n",
    "    parameter to True, generate random lengths between 2 and 4 segments long (inclusive) by setting it to \n",
    "    False, or use their own given transcripts by setting the parameter equal to a list of lengths they want\n",
    "    to use. file_name gives the name of the file that should be written to as a FASTA file\"\"\"\n",
    "    \n",
    "    arc_transcripts = [1]*S\n",
    "    \n",
    "    # Check if the user wants the random, defualt, or specified lengths\n",
    "    if use_default_lengths == False:\n",
    "        L_use = [1]*S\n",
    "    \n",
    "        for idx, element in enumerate(L_use):\n",
    "            L_use[idx] = rand.choice([2*S_len, 3*S_len, 4*S_len])    \n",
    "            \n",
    "    elif use_default_lengths == True:\n",
    "        L_use = L\n",
    "        \n",
    "    elif isinstance(use_default_lengths, list):\n",
    "        L_use = use_default_lengths\n",
    "        \n",
    "    \n",
    "    # Iterate over each transcript in the Arc locus\n",
    "    for transcript_num, transcript_len in enumerate(L_use):\n",
    "        seg_start = transcript_num*S_len\n",
    "        \n",
    "        # Correct for off-by-one error for non-zero segment start indices\n",
    "        if seg_start > 0:\n",
    "            seg_start -= 1  \n",
    "        \n",
    "        # Test if this iteration's transcript wraps fully around the circle, and then add the arc_locus\n",
    "        # splits accordingly\n",
    "        if (seg_start+1) + transcript_len > len(arc_locus):\n",
    "            first_seg = arc_locus[seg_start:]\n",
    "            arc_transcripts[transcript_num] = first_seg + arc_locus[:(transcript_len-len(first_seg))]   \n",
    "        else:\n",
    "            arc_transcripts[transcript_num] = arc_locus[seg_start:seg_start+transcript_len]\n",
    "      \n",
    "    # Write the arc_transcripts to a FASTA file\n",
    "    file = open(file_name, \"w\")\n",
    "    \n",
    "    for transcript_num, transcript_seq in enumerate(arc_transcripts):\n",
    "        fasta_list = [transcript_seq[i * 80:(i + 1) * 80] for i in range((len(transcript_seq) + 80 - 1)\n",
    "                                                                         // 80 )]  \n",
    "        file.write(\">\"+\"Arc\"+str(transcript_num+1)+\"\\n\")\n",
    "        \n",
    "        for line in fasta_list:\n",
    "            new_line = \"\".join(line)\n",
    "            file.write(new_line+\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    return arc_transcripts\n",
    "    \n",
    "def create_arc_reads(arc_transcripts, use_random_abund, file_name):\n",
    "    \n",
    "    v_use = []\n",
    "    arc_reads = []\n",
    "    file = open(file_name, \"w\")\n",
    "    \n",
    "    # Check if the user wants random abundances\n",
    "    if use_random_abund == True:\n",
    "        for i in range(10):\n",
    "            v_use.append(rand.uniform(0,1))\n",
    "        v_use = [j/sum(v_use) for j in v_use]\n",
    "    elif use_random_abund == False:\n",
    "        v_use = v_norm     \n",
    "    else: v_use = use_random_abund\n",
    "    \n",
    "    # Iterate 100000 times, creating a new read each time\n",
    "    for i in range(N):\n",
    "        # Get a fragment of length read <= fragment <= transcript\n",
    "        transcript_idx = rand.choice(len(arc_transcripts), p=v_use) # np did not work for square list\n",
    "        transcript = arc_transcripts[transcript_idx]\n",
    "        transcript_len = len(transcript)\n",
    "        frag_len = trunc_gaussian(frag_mean, frag_sd, transcript_len, R_len)\n",
    "        start_idx = rand.randint(0, (transcript_len-frag_len)+1)\n",
    "        frag = transcript[start_idx:start_idx+frag_len]\n",
    "        \n",
    "        # With probability 1/2, take the reverse compliment of the frragment when creating the read to \n",
    "        # reflect the fact that our reads can come from either strand of the cDNA sequence. Note that we\n",
    "        # write to the file each time instead of storing the sequences in a data structure to save time\n",
    "        # and memory\n",
    "        if rand.uniform(0,1) > 0.5:\n",
    "            #arc_reads.append(\"\".join(frag[:75])) want to test speed wrtiting directly to file, no list\n",
    "            frag_str = \"\".join(frag[:75])\n",
    "            frag_str = base_error(frag_str, 0.001)\n",
    "            file.write(\"@read\"+str(i)+\"\\n\")\n",
    "            file.write(frag_str+\"\\n\")\n",
    "            file.write(\"+\\n\")\n",
    "            file.write(\"I\"*len(frag_str)+\"\\n\")\n",
    "        else:\n",
    "            rc_frag_str = \"\".join(reverse_comp(frag))\n",
    "            rc_frag_str = base_error(rc_frag_str, 0.001)\n",
    "            file.write(\"@read\"+str(i)+\"\\n\")\n",
    "            file.write(rc_frag_str+\"\\n\")\n",
    "            file.write(\"+\\n\")\n",
    "            file.write(\"I\"*len(rc_frag_str)+\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Testing Kallisto with a Postive Control\n",
    "\n",
    "Now, with all of our functions written and parameter values set, let's create a simulated Arc Locus and transcriptome with the transcription abundances that we found in our original findings and see if Kallisto gets it correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.550817251205444\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time() # Record the time when we start our function pipeline\n",
    "\n",
    "# Simulate arc transcriptome with the parameters from our PhD thesis conclusions\n",
    "sim_arc_locus_1 = create_arc_loc(False)\n",
    "sim_transcriptome_1 = create_arc_transcriptome(sim_arc_locus_1, True, \"sim_transcriptome_1.fasta\")\n",
    "sim_reads_1 = create_arc_reads(sim_transcriptome_1, False, \"sim_reads_1.fastq\")\n",
    "\n",
    "end = time.time() # Record the time when we end our function pipeline\n",
    "\n",
    "print(end-start) # Print the difference to see the total run time to create the FASTQ read file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick note, generating 100,000 reads takes under a minute, which is reasonable. Notice however that if we wanted to make this program scalable to create many more reads, we could use multi-threading to create many reads at once, and then save those reads to a list and write them to a file at the end. However, in that case we would need to be careful to consider memory usage (storing a massive list of millions of reads will use substansial RAM). However, since this is just a simulation, under a minute is an acceptable run time for our purposes here so multi-threading is not necessary.\n",
    "\n",
    "Now that we have a FASTA file of our simulated transcriptome, and a FASTQ file for our simulated reads, we can feed the simulated data to Kallisto and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file sim_transcriptome_1.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 19 contigs and contains 10000 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 10,000\n",
      "[index] number of equivalence classes: 26\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: sim_reads_1.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,985 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 55 rounds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! kallisto index -i sim_kallisto_transcripts_1.idx sim_transcriptome_1.fasta\n",
    "! kallisto quant -i sim_kallisto_transcripts_1.idx -o sim_kallisto_output_1 --single -l 150 -s 20 sim_reads_1.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Moriarty tpm</th>\n",
       "      <th>Simulated tpm</th>\n",
       "      <th>Correct tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20570.4</td>\n",
       "      <td>21816.0</td>\n",
       "      <td>5904.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55436.5</td>\n",
       "      <td>50026.7</td>\n",
       "      <td>57564.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279105.0</td>\n",
       "      <td>284044.0</td>\n",
       "      <td>286346.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75939.3</td>\n",
       "      <td>73338.1</td>\n",
       "      <td>82656.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94504.2</td>\n",
       "      <td>92521.3</td>\n",
       "      <td>93726.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19604.8</td>\n",
       "      <td>21441.5</td>\n",
       "      <td>7872.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82868.8</td>\n",
       "      <td>82128.0</td>\n",
       "      <td>87084.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>85804.8</td>\n",
       "      <td>88821.2</td>\n",
       "      <td>88560.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30472.9</td>\n",
       "      <td>27867.7</td>\n",
       "      <td>21648.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>255693.0</td>\n",
       "      <td>257996.0</td>\n",
       "      <td>268634.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Moriarty tpm  Simulated tpm  Correct tpm\n",
       "0       20570.4        21816.0       5904.1\n",
       "1       55436.5        50026.7      57564.6\n",
       "2      279105.0       284044.0     286346.9\n",
       "3       75939.3        73338.1      82656.8\n",
       "4       94504.2        92521.3      93726.9\n",
       "5       19604.8        21441.5       7872.1\n",
       "6       82868.8        82128.0      87084.9\n",
       "7       85804.8        88821.2      88560.9\n",
       "8       30472.9        27867.7      21648.2\n",
       "9      255693.0       257996.0     268634.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the tpm counts given by kallisto for our simulated data next to Moriarty's tpm counts and our\n",
    "# calculation for what the correct tpm counts should be according to the parameters with which our \n",
    "# simulated data was generated\n",
    "sim_data_1 = pd.read_csv('sim_kallisto_output_1/abundance.tsv', delim_whitespace=True)\n",
    "m_vs_sim1_data = pd.DataFrame({\"Moriarty tpm\":list(m_data[\"tpm\"]), \"Simulated tpm\":list(sim_data_1[\"tpm\"]),\n",
    "                              \"Correct tpm\":calc_correct_tpm(v_norm, L)})\n",
    "m_vs_sim1_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see that Kallisto is giving incorrect TPM values given the parameters this data was generated from. Furthermore, we can see that the TPM counts for our simulated data that was generated according to the parameters we found in our thesis expirement are basically the same as Moriarty's TPM counts, which means that our thesis conclusions are likely correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Debugging Kallisto\n",
    "\n",
    "Now we want to find out why Kallisto is getting the TPM counts wrong. The first thing we notice that is unusual is that the Arc Locus is circular, rather than having a start and an end. This might affect the way Kallisto creates the de Bruijn graph, which could in turn affect its accuracy. We also see that there are many overlapping transcripts (up to 4 in some places), which means that we are relying on maximum likelyhood estimation to assign multi-mapped reads. This could be yet another reason for the error if our Arc Locus somehow violates the assumpotions underlying ML estimation. Therefore, we first want to test Kallisto's accuracy on the simplest case: a linear Arc Locus with no overlapping transcripts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file test_transcriptome_1.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 10 contigs and contains 9700 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 9,700\n",
      "[index] number of equivalence classes: 10\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: test_reads_1.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,068 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc</th>\n",
       "      <th>Test 1 tpm</th>\n",
       "      <th>Correct tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arc1</td>\n",
       "      <td>8277.14</td>\n",
       "      <td>8008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arc2</td>\n",
       "      <td>38932.90</td>\n",
       "      <td>39039.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arc3</td>\n",
       "      <td>289125.00</td>\n",
       "      <td>291291.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arc4</td>\n",
       "      <td>111711.00</td>\n",
       "      <td>112112.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arc5</td>\n",
       "      <td>126065.00</td>\n",
       "      <td>127127.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arc6</td>\n",
       "      <td>8277.14</td>\n",
       "      <td>8008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arc7</td>\n",
       "      <td>57092.10</td>\n",
       "      <td>59059.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arc8</td>\n",
       "      <td>60160.70</td>\n",
       "      <td>60060.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arc9</td>\n",
       "      <td>22489.60</td>\n",
       "      <td>22022.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arc10</td>\n",
       "      <td>277870.00</td>\n",
       "      <td>273273.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arc  Test 1 tpm  Correct tpm\n",
       "0   Arc1     8277.14       8008.0\n",
       "1   Arc2    38932.90      39039.0\n",
       "2   Arc3   289125.00     291291.3\n",
       "3   Arc4   111711.00     112112.1\n",
       "4   Arc5   126065.00     127127.1\n",
       "5   Arc6     8277.14       8008.0\n",
       "6   Arc7    57092.10      59059.1\n",
       "7   Arc8    60160.70      60060.1\n",
       "8   Arc9    22489.60      22022.0\n",
       "9  Arc10   277870.00     273273.3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test how kallisto performs on the ideal case by generating a transcriptome with no overlap\n",
    "\n",
    "test_transcript_lengths_1 = [1000]*10\n",
    "test_transcriptome_1 = create_arc_transcriptome(sim_arc_locus_1, test_transcript_lengths_1,\n",
    "                                                \"test_transcriptome_1.fasta\")\n",
    "test_reads_1 = create_arc_reads(test_transcriptome_1, False, \"test_reads_1.fastq\")\n",
    "\n",
    "! kallisto index -i test_kallisto_transcripts_1.idx test_transcriptome_1.fasta\n",
    "! kallisto quant -i test_kallisto_transcripts_1.idx -o test_kallisto_output_1 --single -l 150 -s 20 test_reads_1.fastq\n",
    "\n",
    "test_data_1 = pd.read_csv('test_kallisto_output_1/abundance.tsv', delim_whitespace=True)\n",
    "test_data_1 = pd.DataFrame({\"Arc\":list(test_data_1[\"target_id\"]),\n",
    "                            \"Test 1 tpm\":list(test_data_1[\"tpm\"]),\n",
    "                               \"Correct tpm\":calc_correct_tpm(v_norm, test_transcript_lengths_1)})\n",
    "test_data_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, in the ideal case above, Kallisto does an excellent job at estimating the TPM counts for each transcript. Now we want to detirmine if the error on the true Arc Locus is due to the circularity, the overlapping transcripts, or both. First, let's create a linear Arc Locus with overlaps to see if it is only the circularity that is causing the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file test_transcriptome_2.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 17 contigs and contains 11969 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 11,969\n",
      "[index] number of equivalence classes: 23\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: test_reads_2.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,949 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc</th>\n",
       "      <th>Test 2 tpm</th>\n",
       "      <th>Correct tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arc1</td>\n",
       "      <td>6365.35</td>\n",
       "      <td>5904.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arc2</td>\n",
       "      <td>59832.10</td>\n",
       "      <td>57564.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arc3</td>\n",
       "      <td>286153.00</td>\n",
       "      <td>286346.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arc4</td>\n",
       "      <td>83541.50</td>\n",
       "      <td>82656.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arc5</td>\n",
       "      <td>80836.00</td>\n",
       "      <td>93726.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arc6</td>\n",
       "      <td>26107.90</td>\n",
       "      <td>7872.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arc7</td>\n",
       "      <td>82852.50</td>\n",
       "      <td>87084.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arc8</td>\n",
       "      <td>84094.20</td>\n",
       "      <td>88560.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arc9</td>\n",
       "      <td>29311.00</td>\n",
       "      <td>21648.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arc10</td>\n",
       "      <td>260906.00</td>\n",
       "      <td>268634.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arc  Test 2 tpm  Correct tpm\n",
       "0   Arc1     6365.35       5904.1\n",
       "1   Arc2    59832.10      57564.6\n",
       "2   Arc3   286153.00     286346.9\n",
       "3   Arc4    83541.50      82656.8\n",
       "4   Arc5    80836.00      93726.9\n",
       "5   Arc6    26107.90       7872.1\n",
       "6   Arc7    82852.50      87084.9\n",
       "7   Arc8    84094.20      88560.9\n",
       "8   Arc9    29311.00      21648.2\n",
       "9  Arc10   260906.00     268634.7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test how kallisto performs on linear arc locus with overlapping transcripts\n",
    "\n",
    "test_arc_locus_2 = create_arc_loc(14000)\n",
    "test_transcriptome_2 = create_arc_transcriptome(test_arc_locus_2, True,\n",
    "                                                \"test_transcriptome_2.fasta\")\n",
    "test_reads_2 = create_arc_reads(test_transcriptome_2, False, \"test_reads_2.fastq\")\n",
    "\n",
    "! kallisto index -i test_kallisto_transcripts_2.idx test_transcriptome_2.fasta\n",
    "! kallisto quant -i test_kallisto_transcripts_2.idx -o test_kallisto_output_2 --single -l 150 -s 20 test_reads_2.fastq\n",
    "\n",
    "test_data_2 = pd.read_csv('test_kallisto_output_2/abundance.tsv', delim_whitespace=True)\n",
    "test_data_2 = pd.DataFrame({\"Arc\":list(test_data_2[\"target_id\"]),\n",
    "                            \"Test 2 tpm\":test_data_2[\"tpm\"], \n",
    "                            \"Correct tpm\":calc_correct_tpm(v_norm, L)})\n",
    "test_data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we can see that making the Arc Locus linear increases Kallisto's accuracy for Arc1, but it is still very far off for Arc6. This means that at least part of the problem arises from overlapping transcripts. Also notice that when we make the Arc Locus linear, we reduce the amount of overlap for Arc1 to 0, which means that the increased accuracy for Arc1 may have nothing to do with the linearization of the Arc Locus and instead be attributed to the lack of overlap for transcript 1.\n",
    "\n",
    "In order to test how Kallisto's accuracy changes with the number of overlaps a given transcript has, let's make the abundances uniform and see how Kallisto handle's just finding which reads map to where. We can do this by setting Arc1's length to 4 segements, and all other lengths to 1 segement so that we know the number of overlapping transcripts for each transcript. If the accuracy truly relies on the number of overlapping transcripts, then we should see decreased accuracy for transciripts with the most overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file test_transcriptome_3.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 12 contigs and contains 9790 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 9,790\n",
      "[index] number of equivalence classes: 13\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: test_reads_3.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,336 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc</th>\n",
       "      <th>Test 3 tpm</th>\n",
       "      <th>Correct tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arc1</td>\n",
       "      <td>109048.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arc2</td>\n",
       "      <td>107861.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arc3</td>\n",
       "      <td>108113.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arc4</td>\n",
       "      <td>109224.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arc5</td>\n",
       "      <td>108014.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arc6</td>\n",
       "      <td>26058.2</td>\n",
       "      <td>27027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arc7</td>\n",
       "      <td>107138.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arc8</td>\n",
       "      <td>107215.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arc9</td>\n",
       "      <td>107358.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arc10</td>\n",
       "      <td>109971.0</td>\n",
       "      <td>108108.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arc  Test 3 tpm  Correct tpm\n",
       "0   Arc1    109048.0     108108.1\n",
       "1   Arc2    107861.0     108108.1\n",
       "2   Arc3    108113.0     108108.1\n",
       "3   Arc4    109224.0     108108.1\n",
       "4   Arc5    108014.0     108108.1\n",
       "5   Arc6     26058.2      27027.0\n",
       "6   Arc7    107138.0     108108.1\n",
       "7   Arc8    107215.0     108108.1\n",
       "8   Arc9    107358.0     108108.1\n",
       "9  Arc10    109971.0     108108.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test kallisto's performance for when the only difference between the transcripts is the number of\n",
    "# overlapping transcripts\n",
    "\n",
    "test_transcript_lengths_3 = [1000, 1000, 1000, 1000, 1000, 4000, 1000, 1000, 1000, 1000]\n",
    "test_transcript_abunds_3 = [0.1]*10\n",
    "\n",
    "test_arc_locus_3 = create_arc_loc(False)\n",
    "test_transcriptome_3 = create_arc_transcriptome(test_arc_locus_3, test_transcript_lengths_3,\n",
    "                                                \"test_transcriptome_3.fasta\")\n",
    "test_reads_3 = create_arc_reads(test_transcriptome_3, test_transcript_abunds_3, \"test_reads_3.fastq\")\n",
    "\n",
    "! kallisto index -i test_kallisto_transcripts_3.idx test_transcriptome_3.fasta\n",
    "! kallisto quant -i test_kallisto_transcripts_3.idx -o test_kallisto_output_3 --single -l 150 -s 20 test_reads_3.fastq\n",
    "\n",
    "test_data_3 = pd.read_csv('test_kallisto_output_3/abundance.tsv', delim_whitespace=True)\n",
    "test_data_3 = pd.DataFrame({\"Arc\":list(test_data_3[\"target_id\"]),\n",
    "                            \"Test 3 tpm\":test_data_3[\"tpm\"], \n",
    "                            \"Correct tpm\":calc_correct_tpm(test_transcript_abunds_3, test_transcript_lengths_3)})\n",
    "test_data_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, there is no strong correlation between number of overlapping transcripts and Kallisto's accuracy when the abundances are all the same. Thinking back to Kallisto's origional error for our simulated data with the parameters from our thesis conclusion, we notice that the two transcripts that Kallisto performed poorly on (Arc1 and Arc6) were also the two with the lowest abundances. Therefore, it could be that Kallisto's accuracy is affected by a combination of both relative abundances and overlapping transcripts. Therefore, let's repeat the test run above, but set the transcript with the most overlap (Arc6) to also have either a very high abundance or a very low abundance. Our hypothesis is that Kallisto will over-estimate the TPM counts when the abundance is relativly low, and underestimate the TPM counts when the abundances are very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file test_transcriptome_4.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 12 contigs and contains 9790 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 9,790\n",
      "[index] number of equivalence classes: 13\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: test_reads_4.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,294 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc</th>\n",
       "      <th>Test 4 tpm</th>\n",
       "      <th>Correct tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arc1</td>\n",
       "      <td>110461.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arc2</td>\n",
       "      <td>109469.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arc3</td>\n",
       "      <td>113608.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arc4</td>\n",
       "      <td>112178.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arc5</td>\n",
       "      <td>112351.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arc6</td>\n",
       "      <td>4201.31</td>\n",
       "      <td>2518.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arc7</td>\n",
       "      <td>106494.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arc8</td>\n",
       "      <td>110204.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arc9</td>\n",
       "      <td>109806.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arc10</td>\n",
       "      <td>111227.00</td>\n",
       "      <td>110831.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arc  Test 4 tpm  Correct tpm\n",
       "0   Arc1   110461.00     110831.2\n",
       "1   Arc2   109469.00     110831.2\n",
       "2   Arc3   113608.00     110831.2\n",
       "3   Arc4   112178.00     110831.2\n",
       "4   Arc5   112351.00     110831.2\n",
       "5   Arc6     4201.31       2518.9\n",
       "6   Arc7   106494.00     110831.2\n",
       "7   Arc8   110204.00     110831.2\n",
       "8   Arc9   109806.00     110831.2\n",
       "9  Arc10   111227.00     110831.2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test kallisto's performance for when one transcript has many overlaps and low abundance\n",
    "\n",
    "test_transcript_lengths_4 = [1000, 1000, 1000, 1000, 1000, 4000, 1000, 1000, 1000, 1000]\n",
    "test_transcript_abunds_4 = [0.11, 0.11, 0.11, 0.11, 0.11, 0.01, 0.11, 0.11, 0.11, 0.11]\n",
    "\n",
    "test_arc_locus_4 = create_arc_loc(False)\n",
    "test_transcriptome_4 = create_arc_transcriptome(test_arc_locus_4, test_transcript_lengths_4,\n",
    "                                                \"test_transcriptome_4.fasta\")\n",
    "test_reads_4 = create_arc_reads(test_transcriptome_4, test_transcript_abunds_4, \"test_reads_4.fastq\")\n",
    "\n",
    "! kallisto index -i test_kallisto_transcripts_4.idx test_transcriptome_4.fasta\n",
    "! kallisto quant -i test_kallisto_transcripts_4.idx -o test_kallisto_output_4 --single -l 150 -s 20 test_reads_4.fastq\n",
    "\n",
    "test_data_4 = pd.read_csv('test_kallisto_output_4/abundance.tsv', delim_whitespace=True)\n",
    "test_data_4 = pd.DataFrame({\"Arc\":list(test_data_4[\"target_id\"]),\n",
    "                            \"Test 4 tpm\":test_data_4[\"tpm\"], \n",
    "                            \"Correct tpm\":calc_correct_tpm(test_transcript_abunds_4, test_transcript_lengths_4)})\n",
    "test_data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[build] loading fasta file test_transcriptome_5.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 12 contigs and contains 9790 k-mers \n",
      "\n",
      "\n",
      "[quant] fragment length distribution is truncated gaussian with mean = 150, sd = 20\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 10\n",
      "[index] number of k-mers: 9,790\n",
      "[index] number of equivalence classes: 13\n",
      "[quant] running in single-end mode\n",
      "[quant] will process file 1: test_reads_5.fastq\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 100,000 reads, 99,547 reads pseudoaligned\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 52 rounds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arc</th>\n",
       "      <th>Test 5 tpm</th>\n",
       "      <th>Correct tpm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arc1</td>\n",
       "      <td>87097.2</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arc2</td>\n",
       "      <td>88615.9</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arc3</td>\n",
       "      <td>87503.4</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arc4</td>\n",
       "      <td>85861.0</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arc5</td>\n",
       "      <td>88298.1</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arc6</td>\n",
       "      <td>215008.0</td>\n",
       "      <td>234042.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Arc7</td>\n",
       "      <td>85198.6</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arc8</td>\n",
       "      <td>90208.1</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Arc9</td>\n",
       "      <td>83805.3</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arc10</td>\n",
       "      <td>88404.0</td>\n",
       "      <td>85106.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Arc  Test 5 tpm  Correct tpm\n",
       "0   Arc1     87097.2      85106.4\n",
       "1   Arc2     88615.9      85106.4\n",
       "2   Arc3     87503.4      85106.4\n",
       "3   Arc4     85861.0      85106.4\n",
       "4   Arc5     88298.1      85106.4\n",
       "5   Arc6    215008.0     234042.6\n",
       "6   Arc7     85198.6      85106.4\n",
       "7   Arc8     90208.1      85106.4\n",
       "8   Arc9     83805.3      85106.4\n",
       "9  Arc10     88404.0      85106.4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test kallisto's performance for when one transcript has many overlaps and high abundance\n",
    "\n",
    "test_transcript_lengths_5 = [1000, 1000, 1000, 1000, 1000, 4000, 1000, 1000, 1000, 1000]\n",
    "test_transcript_abunds_5 = [0.05, 0.05, 0.05, 0.05, 0.05, 0.55, 0.05, 0.05, 0.05, 0.05]\n",
    "\n",
    "test_arc_locus_5 = create_arc_loc(False)\n",
    "test_transcriptome_5 = create_arc_transcriptome(test_arc_locus_5, test_transcript_lengths_5,\n",
    "                                                \"test_transcriptome_5.fasta\")\n",
    "test_reads_5 = create_arc_reads(test_transcriptome_5, test_transcript_abunds_5, \"test_reads_5.fastq\")\n",
    "\n",
    "! kallisto index -i test_kallisto_transcripts_5.idx test_transcriptome_5.fasta\n",
    "! kallisto quant -i test_kallisto_transcripts_5.idx -o test_kallisto_output_5 --single -l 150 -s 20 test_reads_5.fastq\n",
    "\n",
    "test_data_5 = pd.read_csv('test_kallisto_output_5/abundance.tsv', delim_whitespace=True)\n",
    "test_data_5 = pd.DataFrame({\"Arc\":list(test_data_5[\"target_id\"]),\n",
    "                            \"Test 5 tpm\":test_data_5[\"tpm\"], \n",
    "                            \"Correct tpm\":calc_correct_tpm(test_transcript_abunds_5, test_transcript_lengths_5)})\n",
    "test_data_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results above, we see that the results are just as our hypothesis perdicted, with the high overlap/low abundance transcript having its TPM count overestimated and the high overlap/high abundance transcipt having its TPM count underestimated. Therefore, we beleive that soemething goes wrong with Kallisto when a transcript with a relativly high or low abundance also has many overlaps. One thing to note is that in the set up of the Arc Locus, the number of transcript overlaps is closely related to the length of a transcript, which in turn effects our calculation of the TPM vs abundance levels. Therefore, we should keep in mind that there may be some underlying relationship between these three things (abundance, transcript length, and number of transcript overlaps) that might change as you tweak any of the three values. \n",
    "\n",
    "One possible explanation for this behavior would be at the level of maximum likelyhood estimation. For example, say you have 15000 reads that map to three transcripts all of equal length, two of which have regular abundances and one of which has a relatively low abundance (but Kallisto does not know about the abundances). Kallisto's maximum likelyhood estimation might find that the reads were equally likely to have come from any of the three transcripts, in which case it would give 5,000 of the reads to each of the transcripts. Let's say that in reality, 7,250 reads came from each of the two regular abundance transcripts, and 500 reads came from the low abundace transcripts. Notice that the regular transcripts estimates are now off by 2,250 reads, while the low abundance transcript is off by 4,750 reads (over twice as many)! Now, further consider the fact that the error in the read counts relative to the true read count is even worse (7,250/5,000 = 1.45 vs 4,750/250 = 19)! However, to truly test if this is what is happening one would have to dig into the details of the maximum likelyhood calculation, equivilence class counts, and the realtionship between abundance, transcript length, and number of transcript overlaps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def trans_to_nuc_abunds(trans_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of transcription abundances and a vector of transcript lengths, returns the nucelotide \n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(trans_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(trans_abunds_vec)\n",
    "    nuc_abunds_list = np.multiply(trans_abunds_vec, trans_lengths_vec)\n",
    "    nuc_abunds_tot = sum(nuc_abunds_list)\n",
    "    nuc_abunds_list = np.true_divide(nuc_abunds_list, nuc_abunds_tot)\n",
    "    \n",
    "    return nuc_abunds_list\n",
    "\n",
    "def nuc_to_trans_abunds(nuc_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of nucleotide abundances and a vector of transcript lengths, returns the transcript\n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(nuc_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(nuc_abunds_vec)\n",
    "    trans_abunds_list = np.true_divide(nuc_abunds_vec, trans_lengths_vec)\n",
    "    trans_abunds_tot = sum(trans_abunds_list)\n",
    "    trans_abunds_list = np.true_divide(trans_abunds_list, trans_abunds_tot)\n",
    "    \n",
    "    return trans_abunds_list\n",
    "\n",
    "def generate_rand_abunds_and_lens(trans_num, len_range):\n",
    "    \"\"\"\"\"\"\n",
    "    # Generate an (almost) uniformly random vector of transcript abundances\n",
    "    abunds_list = np.random.dirichlet(np.ones(trans_num),size=1)[0]\n",
    "    lens_list = np.random.randint(len_range[0], len_range[1]+1, trans_num)\n",
    "    \n",
    "    return abunds_list, lens_list\n",
    "\n",
    "def create_arc(trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_list = []\n",
    "    \n",
    "    num_segs = len(trans_lens_vec)\n",
    "    seg_list = [i for i in range(num_segs)]\n",
    "    \n",
    "    for start_seg, trans_len in enumerate(trans_lens_vec):\n",
    "        end_seg = start_seg+trans_len\n",
    "        if end_seg > num_segs:\n",
    "            transcript = seg_list[start_seg:]+seg_list[:end_seg-num_segs]\n",
    "            trans_list.append(transcript)\n",
    "            \n",
    "        else: trans_list.append(seg_list[start_seg:end_seg])\n",
    "    \n",
    "    return trans_list\n",
    "\n",
    "def create_reads(trans_vec, trans_abunds_vec, trans_lens_vec, N):\n",
    "    \"\"\"\"\"\"\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    reads_list = []\n",
    "    for i in range(N):\n",
    "        transcript = np.random.choice(trans_vec,p=nuc_abunds_list)\n",
    "        segment = np.random.choice(transcript)\n",
    "        reads_list.append(segment)\n",
    "        \n",
    "    return reads_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06774375, 0.93225625])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'a' must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-ca18db661d4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreads_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_abunds_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_lens_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreads_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-a6e0687689d3>\u001b[0m in \u001b[0;36mcreate_reads\u001b[0;34m(trans_vec, trans_abunds_vec, trans_lens_vec, N)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mtranscript\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnuc_abunds_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0msegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mreads_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'a' must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "reads_list = create_reads(transcript_list, trans_abunds_list, trans_lens_list, 5)\n",
    "reads_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO either the math or the code for this is wrong. I think the problem might even be in the creation of the reads\n",
    "# from the transcriptome (check this first)\n",
    "def calc_nll(reads_vec, trans_vec, trans_abunds_vec, trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    log_probs_list = []\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read in reads_vec:\n",
    "        read_prob_list = []\n",
    "        \n",
    "        # For each read, iterate over each transcript\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            \n",
    "            # If the transcript contains the read sequence, calculate the probability that the read came from this\n",
    "            # trasncript and add it to the probability list for this transcript\n",
    "            if read in transcript:\n",
    "                prob = nuc_abunds_list[idx]/trans_lens_vec[idx]\n",
    "                print(\"prob: \" + str(prob))\n",
    "                read_prob_list.append(prob)\n",
    "        \n",
    "        # Add the total probability\n",
    "        print(\"total: \" + str(np.log(np.sum(read_prob_list))))\n",
    "        log_probs_list.append(np.log(np.sum(read_prob_list)))\n",
    "        print(log_probs_list)\n",
    "    total_nll = -1*np.sum(log_probs_list)\n",
    "    \n",
    "    return total_nll\n",
    "\n",
    "def get_lestrade_ests(reads_vec, trans_vec, trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_num = len(trans_lens_vec)\n",
    "    trans_counts_list = [0]*trans_num\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read in reads_vec:\n",
    "        temp_counts = [0]*trans_num\n",
    "        \n",
    "        # For each read, add a count for each transcript that include the segment that generated the read\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            if read in transcript:\n",
    "                temp_counts[idx] += 1\n",
    "                \n",
    "        # Normalize the counts to add to 1\n",
    "        temp_tot = sum(temp_counts)\n",
    "        temp_counts = np.true_divide(temp_counts, temp_tot)\n",
    "        \n",
    "        # Add the count proportions for each read to the total counts list\n",
    "        trans_counts_list = np.add(trans_counts_list, temp_counts)\n",
    "    \n",
    "    counts_tot = sum(trans_counts_list)\n",
    "    est_nuc_abunds_list = np.true_divide(trans_counts_list, counts_tot)\n",
    "    est_trans_abunds_list = nuc_to_trans_abunds(est_nuc_abunds_list, trans_lens_vec)\n",
    "    \n",
    "    return est_trans_abunds_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prob: 0.07233910583675617\n",
      "prob: 0.11086181573198657\n",
      "prob: 0.006308360926680572\n",
      "total: -1.663317271514626\n",
      "[-1.663317271514626]\n",
      "prob: 0.07233910583675617\n",
      "prob: 0.029863776824219028\n",
      "total: -2.2807953955342386\n",
      "[-1.663317271514626, -2.2807953955342386]\n",
      "prob: 0.11086181573198657\n",
      "prob: 0.006308360926680572\n",
      "total: -2.1441278995907647\n",
      "[-1.663317271514626, -2.2807953955342386, -2.1441278995907647]\n",
      "prob: 0.060489635509298034\n",
      "prob: 0.0025243081005250087\n",
      "prob: 0.008405451272542566\n",
      "total: -2.639185809515329\n",
      "[-1.663317271514626, -2.2807953955342386, -2.1441278995907647, -2.639185809515329]\n",
      "prob: 0.012866593716650375\n",
      "prob: 0.027807774200653695\n",
      "prob: 0.060489635509298034\n",
      "total: -2.291012282769677\n",
      "[-1.663317271514626, -2.2807953955342386, -2.1441278995907647, -2.639185809515329, -2.291012282769677]\n",
      "prob: 0.05555555555555555\n",
      "prob: 0.05555555555555555\n",
      "prob: 0.08333333333333331\n",
      "total: -1.637608789400797\n",
      "[-1.637608789400797]\n",
      "prob: 0.05555555555555555\n",
      "prob: 0.049999999999999996\n",
      "total: -2.24851787172377\n",
      "[-1.637608789400797, -2.24851787172377]\n",
      "prob: 0.05555555555555555\n",
      "prob: 0.08333333333333331\n",
      "total: -1.9740810260220099\n",
      "[-1.637608789400797, -2.24851787172377, -1.9740810260220099]\n",
      "prob: 0.044444444444444446\n",
      "prob: 0.016666666666666663\n",
      "prob: 0.022222222222222223\n",
      "total: -2.4849066497880004\n",
      "[-1.637608789400797, -2.24851787172377, -1.9740810260220099, -2.4849066497880004]\n",
      "prob: 0.022222222222222223\n",
      "prob: 0.022222222222222223\n",
      "prob: 0.044444444444444446\n",
      "total: -2.4203681286504293\n",
      "[-1.637608789400797, -2.24851787172377, -1.9740810260220099, -2.4849066497880004, -2.4203681286504293]\n"
     ]
    }
   ],
   "source": [
    "lestrade_trans_abunds_list = get_lestrade_ests(reads_list, transcript_list, trans_lens_list)\n",
    "true_nll = calc_nll(reads_list, transcript_list, trans_abunds_list, trans_lens_list)\n",
    "lestrade_nll = calc_nll(reads_list, transcript_list, lestrade_trans_abunds_list, trans_lens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True transcript abundances:\n",
      "[0.20604119 0.08506005 0.03664751 0.07920401 0.17229072 0.00718991\n",
      " 0.02394098 0.05589351 0.31576421 0.01796791]\n",
      "\n",
      "Lestrade's transcript abundances:\n",
      "[0.14925373 0.13432836 0.05970149 0.05970149 0.11940299 0.04477612\n",
      " 0.05970149 0.         0.14925373 0.2238806 ]\n",
      "\n",
      "Difference:\n",
      "[0.05678746 0.04926831 0.02305398 0.01950251 0.05288773 0.03758621\n",
      " 0.03576051 0.05589351 0.16651048 0.20591269]\n",
      "\n",
      "\n",
      "Negative log-likelyhood of true parameters:\n",
      "11.018438658924635\n",
      "\n",
      "Negative log-likelyhood of Lestrade's parameters:\n",
      "10.765482465585006\n"
     ]
    }
   ],
   "source": [
    "print(\"True transcript abundances:\")\n",
    "print(trans_abunds_list)\n",
    "print(\"\\nLestrade's transcript abundances:\")\n",
    "print(lestrade_trans_abunds_list)\n",
    "print(\"\\nDifference:\")\n",
    "print(np.abs(np.subtract(trans_abunds_list, lestrade_trans_abunds_list)))\n",
    "\n",
    "print(\"\\n\\nNegative log-likelyhood of true parameters:\")\n",
    "print(true_nll)\n",
    "print(\"\\nNegative log-likelyhood of Lestrade's parameters:\")\n",
    "print(lestrade_nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arc_transcriptome(arc_locus, use_default_lengths, file_name):\n",
    "    \"\"\"Creates a tanscriptome based off an arc locus given as an input and outputs it to a FASTA file with \n",
    "    name \"output\". use_defualt_lengths allows the user to use the hardcoded lengths v by setting the \n",
    "    parameter to True, generate random lengths between 2 and 4 segments long (inclusive) by setting it to \n",
    "    False, or use their own given transcripts by setting the parameter equal to a list of lengths they want\n",
    "    to use. file_name gives the name of the file that should be written to as a FASTA file\"\"\"\n",
    "    \n",
    "    arc_transcripts = [1]*S\n",
    "    \n",
    "    # Check if the user wants the random, defualt, or specified lengths\n",
    "    if use_default_lengths == False:\n",
    "        L_use = [1]*S\n",
    "    \n",
    "        for idx, element in enumerate(L_use):\n",
    "            L_use[idx] = rand.choice([2*S_len, 3*S_len, 4*S_len])    \n",
    "            \n",
    "    elif use_default_lengths == True:\n",
    "        L_use = L\n",
    "        \n",
    "    elif isinstance(use_default_lengths, list):\n",
    "        L_use = use_default_lengths\n",
    "        \n",
    "    \n",
    "    # Iterate over each transcript in the Arc locus\n",
    "    for transcript_num, transcript_len in enumerate(L_use):\n",
    "        seg_start = transcript_num*S_len\n",
    "        \n",
    "        # Correct for off-by-one error for non-zero segment start indices\n",
    "        if seg_start > 0:\n",
    "            seg_start -= 1  \n",
    "        \n",
    "        # Test if this iteration's transcript wraps fully around the circle, and then add the arc_locus\n",
    "        # splits accordingly\n",
    "        if (seg_start+1) + transcript_len > len(arc_locus):\n",
    "            first_seg = arc_locus[seg_start:]\n",
    "            arc_transcripts[transcript_num] = first_seg + arc_locus[:(transcript_len-len(first_seg))]   \n",
    "        else:\n",
    "            arc_transcripts[transcript_num] = arc_locus[seg_start:seg_start+transcript_len]\n",
    "      \n",
    "    # Write the arc_transcripts to a FASTA file\n",
    "    file = open(file_name, \"w\")\n",
    "    \n",
    "    for transcript_num, transcript_seq in enumerate(arc_transcripts):\n",
    "        fasta_list = [transcript_seq[i * 80:(i + 1) * 80] for i in range((len(transcript_seq) + 80 - 1)\n",
    "                                                                         // 80 )]  \n",
    "        file.write(\">\"+\"Arc\"+str(transcript_num+1)+\"\\n\")\n",
    "        \n",
    "        for line in fasta_list:\n",
    "            new_line = \"\".join(line)\n",
    "            file.write(new_line+\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    return arc_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.dirichlet(np.ones(10),size=1)[0]\n",
    "print(test)\n",
    "print(sum(test))\n",
    "test = np.divide(test, sum(test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import re\n",
    "\n",
    "def trans_to_nuc_abunds(trans_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of transcription abundances and a vector of transcript lengths, returns the nucelotide \n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(trans_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(trans_abunds_vec)\n",
    "    nuc_abunds_list = np.multiply(trans_abunds_vec, trans_lengths_vec)\n",
    "    nuc_abunds_tot = sum(nuc_abunds_list)\n",
    "    nuc_abunds_list = np.true_divide(nuc_abunds_list, nuc_abunds_tot)\n",
    "    \n",
    "    return nuc_abunds_list\n",
    "\n",
    "def nuc_to_trans_abunds(nuc_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of nucleotide abundances and a vector of transcript lengths, returns the transcript\n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(nuc_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(nuc_abunds_vec)\n",
    "    trans_abunds_list = np.true_divide(nuc_abunds_vec, trans_lengths_vec)\n",
    "    trans_abunds_tot = sum(trans_abunds_list)\n",
    "    trans_abunds_list = np.true_divide(trans_abunds_list, trans_abunds_tot)\n",
    "    \n",
    "    return trans_abunds_list\n",
    "\n",
    "def generate_rand_abunds_and_lens(trans_num, len_range):\n",
    "    \"\"\"Generates a (nearly) uniform random vector of transcript abundances using the dirichlet distribution, and \n",
    "    random lengths sampled from the range given by a tuple len_range. Both the transcript abundances and the lengths\n",
    "    vectors will have a number of elements equal to trans_num\"\"\"\n",
    "\n",
    "    abunds_list = list(np.random.dirichlet(np.ones(trans_num),size=1)[0])\n",
    "    lens_list = list(np.random.randint(len_range[0], len_range[1]+1, trans_num))\n",
    "    \n",
    "    return abunds_list, lens_list\n",
    "\n",
    "def create_arc(trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_list = []\n",
    "    \n",
    "    num_segs = len(trans_lens_vec)\n",
    "    seg_list = [i for i in range(num_segs)]\n",
    "    \n",
    "    for start_seg, trans_len in enumerate(trans_lens_vec):\n",
    "        end_seg = start_seg+trans_len\n",
    "        if end_seg > num_segs:\n",
    "            transcript = seg_list[start_seg:]+seg_list[:end_seg-num_segs]\n",
    "            trans_list.append(list(transcript))\n",
    "            \n",
    "        else: trans_list.append(seg_list[start_seg:end_seg])\n",
    "    \n",
    "    return trans_list\n",
    "\n",
    "def create_reads(trans_vec, trans_abunds_vec, trans_lens_vec, N):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_num = len(trans_vec)\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    reads_list = []\n",
    "    trans_list = []\n",
    "    for i in range(N):\n",
    "        transcript_idx = np.random.choice(trans_num,p=nuc_abunds_list)\n",
    "        transcript = trans_vec[transcript_idx]\n",
    "        trans_list.append(transcript_idx)\n",
    "        segment = np.random.choice(transcript)\n",
    "        reads_list.append(segment)\n",
    "        \n",
    "    return reads_list, trans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abunds_list, trans_lens_list = generate_rand_abunds_and_lens(10, (2,4))\n",
    "transcript_list = create_arc(trans_lens_list)\n",
    "reads_list, trans_list = create_reads(transcript_list, trans_abunds_list, trans_lens_list, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nll(reads_vec, trans_vec, trans_abunds_vec, trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    log_probs_list = []\n",
    "    unique_reads_arr, unique_read_counts_arr = np.unique(reads_vec)\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read in reads_vec:\n",
    "        read_prob_list = []\n",
    "        \n",
    "        # For each read, iterate over each transcript\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            # If the transcript contains the read sequence, calculate the probability that the read came from this\n",
    "            # transcript and add it to the probability list for this transcript (this implicitly sums ove both S and\n",
    "            # T), but the if statement means we only get non-zero probabilities\n",
    "\n",
    "            if read in transcript:\n",
    "                prob = np.log(nuc_abunds_list[idx]/trans_lens_vec[idx])\n",
    "                read_prob_list.append(prob)\n",
    "        \n",
    "        # Add the total probability for every transcript\n",
    "        log_probs_list.append(logsumexp(read_prob_list))\n",
    "        \n",
    "    total_nll = -1*np.sum(log_probs_list)\n",
    "    \n",
    "    return total_nll\n",
    "\n",
    "def get_lestrade_ests(reads_vec, trans_vec, trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_num = len(trans_lens_vec)\n",
    "    trans_counts_list = [0]*trans_num\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read in reads_vec:\n",
    "        temp_counts = [0]*trans_num\n",
    "        \n",
    "        # For each read, add a count for each transcript that include the segment that generated the read\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            if read in transcript:\n",
    "                temp_counts[idx] += 1\n",
    "                \n",
    "        # Normalize the counts to add to 1\n",
    "        temp_tot = sum(temp_counts)\n",
    "        temp_counts = np.true_divide(temp_counts, temp_tot)\n",
    "        \n",
    "        # Add the count proportions for each read to the total counts list\n",
    "        trans_counts_list = np.add(trans_counts_list, temp_counts)\n",
    "    \n",
    "    counts_tot = sum(trans_counts_list)\n",
    "    est_nuc_abunds_list = np.true_divide(trans_counts_list, counts_tot)\n",
    "    est_trans_abunds_list = nuc_to_trans_abunds(est_nuc_abunds_list, trans_lens_vec)\n",
    "    \n",
    "    return est_trans_abunds_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lestrade_trans_abunds_list = get_lestrade_ests(reads_list, transcript_list, trans_lens_list)\n",
    "true_nll = calc_nll(reads_list, transcript_list, trans_abunds_list, trans_lens_list)\n",
    "lestrade_nll = calc_nll(reads_list, transcript_list, lestrade_trans_abunds_list, trans_lens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True transcript abundances:\n",
      "[0.030668138223929, 0.0816204437279238, 0.14667459242858122, 0.040581988482705035, 0.04120482773616693, 0.39232147910046766, 0.025899371634295697, 0.09906493518617411, 0.02314219968545056, 0.11882202379430601]\n",
      "\n",
      "Lestrade's transcript abundances:\n",
      "[0.07304874 0.08583434 0.0936044  0.09446174 0.09884207 0.13502355\n",
      " 0.13188444 0.1076147  0.09835005 0.08133597]\n",
      "\n",
      "Difference:\n",
      "[0.04238061 0.00421389 0.0530702  0.05387975 0.05763724 0.25729793\n",
      " 0.10598507 0.00854977 0.07520785 0.03748606]\n",
      "\n",
      "\n",
      "Negative log-likelyhood of true parameters:\n",
      "2202657.8449061094\n",
      "\n",
      "Negative log-likelyhood of Lestrade's parameters:\n",
      "2232783.7167513254\n",
      "\n",
      "NLL difference: \n",
      "30125.871845216025\n"
     ]
    }
   ],
   "source": [
    "print(\"True transcript abundances:\")\n",
    "print(trans_abunds_list)\n",
    "print(\"\\nLestrade's transcript abundances:\")\n",
    "print(lestrade_trans_abunds_list)\n",
    "print(\"\\nDifference:\")\n",
    "print(np.abs(np.subtract(trans_abunds_list, lestrade_trans_abunds_list)))\n",
    "\n",
    "print(\"\\n\\nNegative log-likelyhood of true parameters:\")\n",
    "print(true_nll)\n",
    "print(\"\\nNegative log-likelyhood of Lestrade's parameters:\")\n",
    "print(lestrade_nll)\n",
    "print(\"\\nNLL difference: \")\n",
    "print(np.abs(true_nll-lestrade_nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-5668b3a0fa30>, line 70)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-5668b3a0fa30>\"\u001b[0;36m, line \u001b[0;32m70\u001b[0m\n\u001b[0;31m    def maximization_step(couunts_vec)\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def read_data_from_file(file_name):\n",
    "    \"\"\"TAKEN FROM LESTRADE AND ADAPTED FOR OUR PURPOSES. Reads a data table of the format output by Lestrade and \n",
    "    returns the read counts and transcript lengths\"\"\"\n",
    "    with open(file_name) as f:\n",
    "        #   The first line is \"The <n> transcripts of the sand mouse Arc locus\"\n",
    "        line  = f.readline()\n",
    "        match = re.search(r'^The (\\d+) transcripts', line)\n",
    "        T     = int(match.group(1))\n",
    "\n",
    "        # The next T lines are \n",
    "        #   <Arcn>  <true_tau> <L> <structure>\n",
    "        # tau's may be present, or obscured (\"xxxxx\")\n",
    "        tau       = np.zeros(T)\n",
    "        L         = np.zeros(T).astype(int)\n",
    "        tau_known = True   # until we see otherwise\n",
    "        for i in range(T):\n",
    "            fields    = f.readline().split()\n",
    "            if fields[1] == \"xxxxx\":\n",
    "                tau_known = False\n",
    "            else:\n",
    "                tau[i] = float(fields[1])\n",
    "            L[i]      = int(fields[2])\n",
    "\n",
    "        # after a blank line,\n",
    "        # 'The <n> read sequences':\n",
    "        line  = f.readline()\n",
    "        line  = f.readline()\n",
    "        match = re.search(r'The (\\d+) read sequences', line)\n",
    "        N     = int(match.group(1))\n",
    "\n",
    "        # the next T lines are \n",
    "        #  <read a-j> <count>\n",
    "        r = np.zeros(T).astype(int)\n",
    "        for k in range(T):\n",
    "            fields = f.readline().split()\n",
    "            r[k]   = fields[1]\n",
    "            \n",
    "    read_counts_list = list(r)\n",
    "#     nuc_abunds_list = np.true_divide(read_counts_list, np.sum(read_counts_list))\n",
    "    \n",
    "    return(read_counts_list, L)\n",
    "\n",
    "def iterate_EM(reads_vec, trans_vec, trans_abunds_vec, trans_lens_vec):\n",
    "    #TODO add a NLL tracker that checks every 100 iterations whether or not it has converged. Plan is to have a\n",
    "    # max number of iterations that can be shortcut when the NLL is static\n",
    "    \n",
    "    nuc_abunds_list = nuc_to_trans_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    trans_num = len(trans_lens_vec)\n",
    "    \n",
    "    for iteration in range(N):\n",
    "        count_arr = np.zeros(10)\n",
    "\n",
    "        # Iterate over each read\n",
    "        for read in reads_vec:\n",
    "            read_prob_list = []\n",
    "            idx_list = []\n",
    "            # For each read, iterate over each transcript\n",
    "            for idx, transcript in enumerate(trans_vec):\n",
    "                # If the read is present in the transcript, add its log probability numerator to read_prob_list\n",
    "                if read in transcript:\n",
    "                    idx_list.append(idx)\n",
    "                    numer = np.log(nuc_abunds_list[idx]/trans_lens_vec[idx])\n",
    "                    read_prob_list.append(numer)\n",
    "\n",
    "            # Normalize the probabilities by subtracting the log probability of the denominator from each element \n",
    "            # of read_prob_list\n",
    "            denom = logsumexp(read_prob_list)\n",
    "            read_prob_list = np.subtract(read_prob_list, denom)\n",
    "\n",
    "            # Add the exponentiated probabilities to the cooresponding transcript count in count_arr\n",
    "            np.add.at(count_arr, idx_list, np.exp(read_prob_list))\n",
    "\n",
    "        new_nuc_abunds = np.divide(counts_arr, np.sum(counts_array))\n",
    "        nuc_abunds_list = new_nuc_abunds\n",
    "\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_trans_abunds_list, test_trans_lens_list = generate_rand_abunds_and_lens(10, (2,4))\n",
    "# test_transcript_list = create_arc(test_trans_lens_list)\n",
    "# test_reads_list, test_trans_list = create_reads(test_transcript_list, test_trans_abunds_list,\n",
    "#                                                 test_trans_lens_list, 50)\n",
    "\n",
    "# test_run = expectation_step(test_reads_list, test_transcript_list, test_trans_abunds_list,\n",
    "#                             test_trans_lens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_counts_list, len_list = read_data_from_file(\"w08-data.out\")\n",
    "arc_transcript_list = create_arc(len_list)\n",
    "print(arc_transcript_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = np.zeros(10)\n",
    "test_idx = [1,2]\n",
    "test_vals = [1,1]\n",
    "\n",
    "np.add.at(test_a, [1,2], 1)\n",
    "print(test_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

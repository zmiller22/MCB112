{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "import re\n",
    "\n",
    "def trans_to_nuc_abunds(trans_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of transcription abundances and a vector of transcript lengths, returns the nucelotide \n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(trans_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(trans_abunds_vec)\n",
    "    nuc_abunds_list = np.multiply(trans_abunds_vec, trans_lengths_vec)\n",
    "    nuc_abunds_tot = sum(nuc_abunds_list)\n",
    "    nuc_abunds_list = np.true_divide(nuc_abunds_list, nuc_abunds_tot)\n",
    "    \n",
    "    return nuc_abunds_list\n",
    "\n",
    "def nuc_to_trans_abunds(nuc_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of nucleotide abundances and a vector of transcript lengths, returns the transcript\n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(nuc_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(nuc_abunds_vec)\n",
    "    trans_abunds_list = np.true_divide(nuc_abunds_vec, trans_lengths_vec)\n",
    "    trans_abunds_tot = sum(trans_abunds_list)\n",
    "    trans_abunds_list = np.true_divide(trans_abunds_list, trans_abunds_tot)\n",
    "    \n",
    "    return trans_abunds_list\n",
    "\n",
    "def generate_rand_abunds_and_lens(trans_num, len_range):\n",
    "    \"\"\"Generates a (nearly) uniform random vector of transcript abundances using the dirichlet distribution, and \n",
    "    random lengths sampled from the range given by a tuple len_range. Both the transcript abundances and the lengths\n",
    "    vectors will have a number of elements equal to trans_num\"\"\"\n",
    "\n",
    "    abunds_list = list(np.random.dirichlet(np.ones(trans_num),size=1)[0])\n",
    "    lens_list = list(np.random.randint(len_range[0], len_range[1]+1, trans_num))\n",
    "    \n",
    "    return abunds_list, lens_list\n",
    "\n",
    "def create_arc(trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_list = []\n",
    "    \n",
    "    num_segs = len(trans_lens_vec)\n",
    "    seg_list = [i for i in range(num_segs)]\n",
    "    \n",
    "    for start_seg, trans_len in enumerate(trans_lens_vec):\n",
    "        end_seg = start_seg+trans_len\n",
    "        if end_seg > num_segs:\n",
    "            transcript = seg_list[start_seg:]+seg_list[:end_seg-num_segs]\n",
    "            trans_list.append(list(transcript))\n",
    "            \n",
    "        else: trans_list.append(seg_list[start_seg:end_seg])\n",
    "    \n",
    "    return trans_list\n",
    "\n",
    "def create_reads(trans_vec, trans_abunds_vec, trans_lens_vec, N):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_num = len(trans_vec)\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    reads_list = []\n",
    "    trans_list = []\n",
    "    for i in range(N):\n",
    "        transcript_idx = np.random.choice(trans_num,p=nuc_abunds_list)\n",
    "        transcript = trans_vec[transcript_idx]\n",
    "        trans_list.append(transcript_idx)\n",
    "        segment = np.random.choice(transcript)\n",
    "        reads_list.append(segment)\n",
    "        \n",
    "    return reads_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_abunds_list, trans_lens_list = generate_rand_abunds_and_lens(10, (2,4))\n",
    "transcript_list = create_arc(trans_lens_list)\n",
    "reads_list = create_reads(transcript_list, trans_abunds_list, trans_lens_list, 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nll(reads_vec, trans_vec, trans_abunds_vec, trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    log_probs_list = []\n",
    "    unique_reads_arr, unique_read_counts_arr = np.unique(reads_vec, return_counts=True)\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read_idx, read in enumerate(unique_reads_arr):\n",
    "        read_prob_list = []\n",
    "        \n",
    "        # For each read, iterate over each transcript\n",
    "        for trans_idx, transcript in enumerate(trans_vec):\n",
    "            \n",
    "            # If the transcript contains the read sequence, calculate the probability that the read came from this\n",
    "            # transcript and add it to the probability list for this transcript (this implicitly sums ove both S and\n",
    "            # T), but the if statement means we only get non-zero probabilities\n",
    "            if read in transcript:\n",
    "                prob = np.log(nuc_abunds_list[trans_idx]/trans_lens_vec[trans_idx])\n",
    "                read_prob_list.append(prob)\n",
    "        \n",
    "        # Add the total log probability for this unique read\n",
    "        total_read_log_prob = logsumexp(read_prob_list)*unique_read_counts_arr[read_idx]\n",
    "        log_probs_list.append(total_read_log_prob)\n",
    "        \n",
    "    total_nll = -1*np.sum(log_probs_list)\n",
    "    \n",
    "    return total_nll\n",
    "\n",
    "def get_lestrade_ests(reads_vec, trans_vec, trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_num = len(trans_lens_vec)\n",
    "    trans_counts_list = [0]*trans_num\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read in reads_vec:\n",
    "        temp_counts = [0]*trans_num\n",
    "        \n",
    "        # For each read, add a count for each transcript that include the segment that generated the read\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            if read in transcript:\n",
    "                temp_counts[idx] += 1\n",
    "                \n",
    "        # Normalize the counts to add to 1\n",
    "        temp_tot = sum(temp_counts)\n",
    "        temp_counts = np.true_divide(temp_counts, temp_tot)\n",
    "        \n",
    "        # Add the count proportions for each read to the total counts list\n",
    "        trans_counts_list = np.add(trans_counts_list, temp_counts)\n",
    "    \n",
    "    counts_tot = sum(trans_counts_list)\n",
    "    est_nuc_abunds_list = np.true_divide(trans_counts_list, counts_tot)\n",
    "    est_trans_abunds_list = nuc_to_trans_abunds(est_nuc_abunds_list, trans_lens_vec)\n",
    "    \n",
    "    return est_trans_abunds_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lestrade_trans_abunds_list = get_lestrade_ests(reads_list, transcript_list, trans_lens_list)\n",
    "true_nll = calc_nll(reads_list, transcript_list, trans_abunds_list, trans_lens_list)\n",
    "lestrade_nll = calc_nll(reads_list, transcript_list, lestrade_trans_abunds_list, trans_lens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True transcript abundances:\n",
      "[0.0910660491030029, 0.07619826048026715, 0.06419228055515133, 0.2855110543267139, 0.02998799094175139, 0.015256709085199752, 0.1443577440157697, 0.01361654095705679, 0.1875771613734522, 0.09223620916163504]\n",
      "\n",
      "Lestrade's transcript abundances:\n",
      "[0.07754012 0.08359557 0.12727032 0.13948558 0.1280294  0.09492747\n",
      " 0.08756942 0.08018153 0.09884003 0.08256056]\n",
      "\n",
      "Difference:\n",
      "[0.01352593 0.00739731 0.06307804 0.14602547 0.09804141 0.07967076\n",
      " 0.05678832 0.06656498 0.08873713 0.00967565]\n",
      "\n",
      "\n",
      "Negative log-likelyhood of true parameters:\n",
      "2261369.6214148276\n",
      "\n",
      "Negative log-likelyhood of Lestrade's parameters:\n",
      "2277064.5178100616\n",
      "\n",
      "NLL difference: \n",
      "15694.896395233925\n"
     ]
    }
   ],
   "source": [
    "print(\"True transcript abundances:\")\n",
    "print(trans_abunds_list)\n",
    "print(\"\\nLestrade's transcript abundances:\")\n",
    "print(lestrade_trans_abunds_list)\n",
    "print(\"\\nDifference:\")\n",
    "print(np.abs(np.subtract(trans_abunds_list, lestrade_trans_abunds_list)))\n",
    "\n",
    "print(\"\\n\\nNegative log-likelyhood of true parameters:\")\n",
    "print(true_nll)\n",
    "print(\"\\nNegative log-likelyhood of Lestrade's parameters:\")\n",
    "print(lestrade_nll)\n",
    "print(\"\\nNLL difference: \")\n",
    "print(np.abs(true_nll-lestrade_nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_file(file_name):\n",
    "    \"\"\"TAKEN FROM LESTRADE AND ADAPTED FOR OUR PURPOSES. Reads a data table of the format output by Lestrade and \n",
    "    returns the read counts and transcript lengths\"\"\"\n",
    "    with open(file_name) as f:\n",
    "        #   The first line is \"The <n> transcripts of the sand mouse Arc locus\"\n",
    "        line  = f.readline()\n",
    "        match = re.search(r'^The (\\d+) transcripts', line)\n",
    "        T     = int(match.group(1))\n",
    "\n",
    "        # The next T lines are \n",
    "        #   <Arcn>  <true_tau> <L> <structure>\n",
    "        # tau's may be present, or obscured (\"xxxxx\")\n",
    "        tau       = np.zeros(T)\n",
    "        L         = np.zeros(T).astype(int)\n",
    "        tau_known = True   # until we see otherwise\n",
    "        for i in range(T):\n",
    "            fields    = f.readline().split()\n",
    "            if fields[1] == \"xxxxx\":\n",
    "                tau_known = False\n",
    "            else:\n",
    "                tau[i] = float(fields[1])\n",
    "            L[i]      = int(fields[2])\n",
    "\n",
    "        # after a blank line,\n",
    "        # 'The <n> read sequences':\n",
    "        line  = f.readline()\n",
    "        line  = f.readline()\n",
    "        match = re.search(r'The (\\d+) read sequences', line)\n",
    "        N     = int(match.group(1))\n",
    "\n",
    "        # the next T lines are \n",
    "        #  <read a-j> <count>\n",
    "        r = np.zeros(T).astype(int)\n",
    "        for k in range(T):\n",
    "            fields = f.readline().split()\n",
    "            r[k]   = fields[1]\n",
    "            \n",
    "    read_counts_list = list(r)\n",
    "#     nuc_abunds_list = np.true_divide(read_counts_list, np.sum(read_counts_list))\n",
    "    \n",
    "    return(read_counts_list, L)\n",
    "\n",
    "def run_EM_optimization(reads_vec, trans_vec, trans_lens_vec, N):\n",
    "    \"\"\"\"\"\"\n",
    "    #TODO add a NLL tracker that checks every 100 iterations whether or not it has converged. Plan is to have a\n",
    "    # max number of iterations that can be shortcut when the NLL is static\n",
    "    initial_trans_abunds = generate_rand_abunds_and_lens(len(trans_lens_vec), (1,1))[0]\n",
    "        \n",
    "    nuc_abunds_list = nuc_to_trans_abunds(initial_trans_abunds, trans_lens_vec)\n",
    "    trans_num = len(trans_lens_vec)\n",
    "    unique_reads_arr, unique_read_counts_arr = np.unique(reads_vec, return_counts=True)\n",
    "    \n",
    "    for iteration in range(N):\n",
    "        count_arr = np.zeros(10)\n",
    "\n",
    "        # Iterate over each read\n",
    "        for read_idx, read in enumerate(unique_reads_arr):\n",
    "            read_prob_list = []\n",
    "            idx_list = []\n",
    "            # For each read, iterate over each transcript\n",
    "            for trans_idx, transcript in enumerate(trans_vec):\n",
    "                # If the read is present in the transcript, add its log probability numerator to read_prob_list\n",
    "                if read in transcript:\n",
    "                    idx_list.append(trans_idx)\n",
    "                    numer = np.log(nuc_abunds_list[trans_idx]/trans_lens_vec[trans_idx])\n",
    "                    read_prob_list.append(numer)\n",
    "\n",
    "            # Normalize the probabilities by subtracting the log probability of the denominator from each element \n",
    "            # of read_prob_list\n",
    "            denom = logsumexp(read_prob_list)\n",
    "            read_prob_list = np.subtract(read_prob_list, denom)\n",
    "\n",
    "            # Add the exponentiated probabilities to the cooresponding transcript count in count_arr\n",
    "            total_read_counts = np.multiply(np.exp(read_prob_list),unique_read_counts_arr[read_idx])\n",
    "            np.add.at(count_arr, idx_list, total_read_counts)\n",
    "\n",
    "        new_nuc_abunds = np.divide(count_arr, np.sum(count_arr))\n",
    "        nuc_abunds_list = new_nuc_abunds\n",
    "        \n",
    "    final_trans_abunds_list = nuc_to_trans_abunds(nuc_abunds_list, trans_lens_vec)\n",
    "    \n",
    "    return final_trans_abunds_list\n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_counts_list, trans_lens_list = read_data_from_file(\"w08-data.out\")\n",
    "reads_list = []\n",
    "for read_idx, read_count in enumerate(read_counts_list):\n",
    "    reads_list += [read_idx]*read_count\n",
    "    \n",
    "arc_transcript_list = create_arc(trans_lens_list)\n",
    "\n",
    "my_est_abunds_arr = run_EM_optimization(reads_list, arc_transcript_list, trans_lens_list, 5000)\n",
    "lestrade_est_abunds_list = get_lestrade_ests(reads_list, arc_transcript_list, trans_lens_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My estimated transcript abundances:\n",
      "[0.052547991659394534, 0.09773877184556601, 0.06310520652617199, 0.11641676872967749, 0.04396742405287846, 0.3027524978564163, 0.001903577712704212, 0.07373468298268719, 0.061057469565215794, 0.18677560906928808]\n",
      "\n",
      "Lestrade's estimated transcript abundances:\n",
      "[0.0896395  0.09112976 0.07383159 0.10491783 0.11192892 0.12457224\n",
      " 0.11018329 0.08591525 0.09649783 0.11138378]\n",
      "\n",
      "Difference:\n",
      "[0.03709151 0.00660901 0.01072639 0.01149894 0.0679615  0.17818026\n",
      " 0.10827971 0.01218057 0.03544036 0.07539183]\n",
      "\n",
      "\n",
      "Negative log-likelyhood of true parameters:\n",
      "2238099.5084570553\n",
      "\n",
      "Negative log-likelyhood of Lestrade's parameters:\n",
      "2253910.9353717305\n",
      "\n",
      "NLL difference: \n",
      "15811.426914675161\n"
     ]
    }
   ],
   "source": [
    "my_nll = calc_nll(reads_list, arc_transcript_list, my_est_abunds_arr, trans_lens_list)\n",
    "lestrade_nll = calc_nll(reads_list, arc_transcript_list, lestrade_est_abunds_list, trans_lens_list)\n",
    "print(\"My estimated transcript abundances:\")\n",
    "print(list(my_est_abunds_arr))\n",
    "print(\"\\nLestrade's estimated transcript abundances:\")\n",
    "print(lestrade_est_abunds_list)\n",
    "print(\"\\nDifference:\")\n",
    "print(np.abs(np.subtract(my_est_abunds_arr, lestrade_est_abunds_list)))\n",
    "\n",
    "print(\"\\n\\nNegative log-likelyhood of my parameters:\")\n",
    "print(my_nll)\n",
    "print(\"\\nNegative log-likelyhood of Lestrade's parameters:\")\n",
    "print(lestrade_nll)\n",
    "print(\"\\nNLL difference: \")\n",
    "print(np.abs(my_nll-lestrade_nll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lestrade_est_abunds_list = [0.090, 0.091, 0.074, 0.105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06963542720083009, 0.04718356031016843, 0.11692878358934058, 0.0041043037149485085, 0.11824229985706934, 0.3895101241598039, 0.04888426066500686, 0.062437693303916846, 0.012126218729151898, 0.13094732846976345]\n",
      "[6.67905160e-02 4.80052874e-02 1.16974740e-01 2.82115473e-08\n",
      " 1.20862588e-01 3.89282368e-01 5.44769730e-02 6.17717412e-02\n",
      " 1.32907174e-02 1.28545041e-01]\n",
      "[2.84491122e-03 8.21727077e-04 4.59562844e-05 4.10427550e-03\n",
      " 2.62028840e-03 2.27756226e-04 5.59271234e-03 6.65952154e-04\n",
      " 1.16449863e-03 2.40228762e-03]\n"
     ]
    }
   ],
   "source": [
    "test_trans_abunds_list, test_trans_lens_list = generate_rand_abunds_and_lens(10, (2,4))\n",
    "test_transcript_list = create_arc(test_trans_lens_list)\n",
    "test_reads_list = create_reads(test_transcript_list, test_trans_abunds_list,\n",
    "                                                test_trans_lens_list, 10000)\n",
    "\n",
    "test_run = iterate_EM(test_reads_list, test_transcript_list,\n",
    "                            test_trans_lens_list, 1000)\n",
    "\n",
    "print(test_trans_abunds_list)\n",
    "print(test_run)\n",
    "print(np.abs(np.subtract(test_trans_abunds_list, test_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_counts_list, len_list = read_data_from_file(\"w08-data.out\")\n",
    "arc_transcript_list = create_arc(len_list)\n",
    "print(arc_transcript_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = np.zeros(10)\n",
    "test_idx = [1,2]\n",
    "test_vals = [1,1]\n",
    "\n",
    "np.add.at(test_a, [1,2], 1)\n",
    "print(test_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

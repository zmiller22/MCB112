{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "def trans_to_nuc_abunds(trans_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of transcription abundances and a vector of transcript lengths, returns the nucelotide \n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(trans_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(trans_abunds_vec)\n",
    "    nuc_abunds_list = [trans_abunds_vec[i]*trans_lengths_vec[i] for i in range(num_transcripts)]\n",
    "    nuc_abunds_tot = sum(nuc_abunds_list)\n",
    "    nuc_abunds_list = [abund/nuc_abunds_tot for abund in nuc_abunds_list]\n",
    "    \n",
    "    return nuc_abunds_list\n",
    "\n",
    "def nuc_to_trans_abunds(nuc_abunds_vec, trans_lengths_vec):\n",
    "    \"\"\"Given a vector of nucleotide abundances and a vector of transcript lengths, returns the transcript\n",
    "    abundances as a list\"\"\"\n",
    "    \n",
    "    if len(nuc_abunds_vec) != len(trans_lengths_vec): return False\n",
    "    \n",
    "    num_transcripts = len(nuc_abunds_vec)\n",
    "    trans_abunds_list = [nuc_abunds_vec[i]/trans_lengths_vec[i] for i in range(num_transcripts)]\n",
    "    trans_abunds_tot = sum(trans_abunds_list)\n",
    "    trans_abunds_list = [abund/trans_abunds_tot for abund in trans_abunds_list]\n",
    "    \n",
    "    return trans_abunds_list\n",
    "\n",
    "def create_arc(trans_lens_vec):\n",
    "    \"\"\"\"\"\"\n",
    "    trans_list = []\n",
    "    \n",
    "    num_segs = len(trans_lens_vec)\n",
    "    seg_list = [i for i in range(num_segs)]\n",
    "    \n",
    "    for start_seg, trans_len in enumerate(trans_lens_vec):\n",
    "        end_seg = start_seg+trans_len\n",
    "        if end_seg > num_segs:\n",
    "            transcript = seg_list[start_seg:]+seg_list[:end_seg-num_segs]\n",
    "            trans_list.append(transcript)\n",
    "            \n",
    "        else: trans_list.append(seg_list[start_seg:end_seg])\n",
    "    \n",
    "    return trans_list\n",
    "\n",
    "def create_reads(trans_vec, trans_abunds_vec, trans_lens_vec, N):\n",
    "    \"\"\"\"\"\"\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    reads_list = []\n",
    "    for i in range(N):\n",
    "        transcript = np.random.choice(trans_vec,p=nuc_abunds_list)\n",
    "        segment = np.random.choice(transcript)\n",
    "        reads_list.append(segment)\n",
    "        \n",
    "    return reads_list\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0], [1], [2, 0, 1]]\n",
      "[1, 0, 1, 1, 1, 2, 0, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "trans_lens_list = [1,1,3]\n",
    "trans_abunds_list = [0.2, 0.6, 0.2]\n",
    "transcript_list = create_arc(trans_lens_list)\n",
    "reads_list = create_reads(transcript_list, trans_abunds_list, trans_lens_list, 10)\n",
    "print(transcript_list)\n",
    "print(reads_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nll(reads_vec, trans_vec, trans_abunds_vec, trans_lens_vec):\n",
    "    nuc_abunds_list = trans_to_nuc_abunds(trans_abunds_vec, trans_lens_vec)\n",
    "    log_probs_list = []\n",
    "    \n",
    "    for read in reads_vec:\n",
    "        read_prob_list = []\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            if read in transcript:\n",
    "                prob = np.log(nuc_abunds_list[idx]/trans_lens_vec[idx])\n",
    "                read_prob_list.append(prob)\n",
    "        log_probs_list.append(logsumexp(read_prob_list))\n",
    "        \n",
    "    total_nll = -1*np.sum(log_probs_list)\n",
    "    \n",
    "    return total_nll\n",
    "\n",
    "def get_lestrade_ests(reads_vec, trans_vec, trans_lens_vec):\n",
    "    trans_num = len(trans_lens_vec)\n",
    "    trans_counts_list = [0]*trans_num\n",
    "    \n",
    "    # Iterate over each read\n",
    "    for read in reads_vec:\n",
    "        temp_counts = [0]*trans_num\n",
    "        \n",
    "        # For each read, add a count for each transcript that include the segment that generated the read\n",
    "        for idx, transcript in enumerate(trans_vec):\n",
    "            if read in transcript:\n",
    "                temp_counts[idx] += 1\n",
    "                \n",
    "        # Normalize the counts to add to 1\n",
    "        count_tot = sum(temp_count)\n",
    "        temp_counts = [count/count_tot for count in temp_count]\n",
    "        \n",
    "        # Add the count proportions for each read to the total counts list\n",
    "        trans_counts_list = [trans_counts_list[i]+temp_counts[i] for i in range(trans_num)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.448188143273844\n",
      "18.611371693284106\n"
     ]
    }
   ],
   "source": [
    "wrong_trans_abunds = [0.9, 0.05, 0.05]\n",
    "test_1 = calc_nll(reads_list, transcript_list, trans_abunds_list, trans_lens_list)\n",
    "test_2 = calc_nll(reads_list, transcript_list, wrong_trans_abunds, trans_lens_list)\n",
    "\n",
    "print(test_1)\n",
    "print(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arc_transcriptome(arc_locus, use_default_lengths, file_name):\n",
    "    \"\"\"Creates a tanscriptome based off an arc locus given as an input and outputs it to a FASTA file with \n",
    "    name \"output\". use_defualt_lengths allows the user to use the hardcoded lengths v by setting the \n",
    "    parameter to True, generate random lengths between 2 and 4 segments long (inclusive) by setting it to \n",
    "    False, or use their own given transcripts by setting the parameter equal to a list of lengths they want\n",
    "    to use. file_name gives the name of the file that should be written to as a FASTA file\"\"\"\n",
    "    \n",
    "    arc_transcripts = [1]*S\n",
    "    \n",
    "    # Check if the user wants the random, defualt, or specified lengths\n",
    "    if use_default_lengths == False:\n",
    "        L_use = [1]*S\n",
    "    \n",
    "        for idx, element in enumerate(L_use):\n",
    "            L_use[idx] = rand.choice([2*S_len, 3*S_len, 4*S_len])    \n",
    "            \n",
    "    elif use_default_lengths == True:\n",
    "        L_use = L\n",
    "        \n",
    "    elif isinstance(use_default_lengths, list):\n",
    "        L_use = use_default_lengths\n",
    "        \n",
    "    \n",
    "    # Iterate over each transcript in the Arc locus\n",
    "    for transcript_num, transcript_len in enumerate(L_use):\n",
    "        seg_start = transcript_num*S_len\n",
    "        \n",
    "        # Correct for off-by-one error for non-zero segment start indices\n",
    "        if seg_start > 0:\n",
    "            seg_start -= 1  \n",
    "        \n",
    "        # Test if this iteration's transcript wraps fully around the circle, and then add the arc_locus\n",
    "        # splits accordingly\n",
    "        if (seg_start+1) + transcript_len > len(arc_locus):\n",
    "            first_seg = arc_locus[seg_start:]\n",
    "            arc_transcripts[transcript_num] = first_seg + arc_locus[:(transcript_len-len(first_seg))]   \n",
    "        else:\n",
    "            arc_transcripts[transcript_num] = arc_locus[seg_start:seg_start+transcript_len]\n",
    "      \n",
    "    # Write the arc_transcripts to a FASTA file\n",
    "    file = open(file_name, \"w\")\n",
    "    \n",
    "    for transcript_num, transcript_seq in enumerate(arc_transcripts):\n",
    "        fasta_list = [transcript_seq[i * 80:(i + 1) * 80] for i in range((len(transcript_seq) + 80 - 1)\n",
    "                                                                         // 80 )]  \n",
    "        file.write(\">\"+\"Arc\"+str(transcript_num+1)+\"\\n\")\n",
    "        \n",
    "        for line in fasta_list:\n",
    "            new_line = \"\".join(line)\n",
    "            file.write(new_line+\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "    return arc_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [0]*5\n",
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
